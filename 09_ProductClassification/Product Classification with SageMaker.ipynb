{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Classification (Category)\n",
    "**Scenario**: I have an online marketplace platform and when my users create a new advertising, sometimes they put the item in the wrong Category. As a side effect, that particular product will not be found by the recommendation engine nor if the customers decide to navigate through the Category taxonomy. \n",
    "\n",
    "**Business Challenge**: How can I alert my users when they are about to make a mistake of registering an item in a wrong Category?\n",
    "\n",
    "**Data Set**: I have a cleaned list of short descriptions and the actual category id of some products\n",
    "\n",
    "|Short description | Category |\n",
    "|---|---|\n",
    "|legging mulher elastica karen stp v verde|6|\n",
    "|rasteira via mia lace up preta|2|\n",
    "\n",
    "\n",
    "**Solution**: I need a ML classifier model that will receive as input the short description of a product and predict it's correct Category. So, I will use a basic technique to encode the textual field into a vector, then train a RandomForest to give me the correct Category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer,TfidfTransformer\n",
    "from sklearn import preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isfile('data/dataset.csv'):\n",
    "    !curl -s https://spock.cloud/ai-workshop/product_classification.tar.gz | tar -xz -C ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/dataset.csv', sep=',', encoding='utf-8')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.groupby(['category'])['category'].count().plot(kind='bar', figsize=(20,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the data and split the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = data.product_name.values\n",
    "y = data.category.astype('category').cat.codes.values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42, stratify=y)\n",
    "\n",
    "pd.DataFrame(data={'product_name': X_train, 'category': y_train}).to_csv('data/products_cat_train.csv', index=None)\n",
    "pd.DataFrame(data={'product_name': X_test, 'category': y_test}).to_csv('data/products_cat_test.csv', index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "clean_data = data.groupby('sub_category').filter(lambda x : len(x)>2)\n",
    "X_sub = clean_data.product_name.values\n",
    "y_sub = clean_data.sub_category.astype('category').cat.codes.values\n",
    "\n",
    "X_train_sub, X_test_sub, y_train_sub, y_test_sub = train_test_split(X_sub, y_sub, test_size=0.33, random_state=42, stratify=y_sub)\n",
    "\n",
    "pd.DataFrame(data={'product_name': X_train_sub, 'sub_category': y_train_sub}).to_csv('data/products_subcat_train.csv', index=None)\n",
    "pd.DataFrame(data={'product_name': X_test_sub, 'sub_category': y_test_sub}).to_csv('data/products_subcat_test.csv', index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we'll create a scikit-learn script to train our classifier with Random Forest\n",
    "As you will see, the data input is in string format. We'll vectorize it with a scikit-learn feature called **TfidfVectorizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile src/products.py\n",
    "import argparse\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.externals import joblib\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.externals import joblib\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import scipy.sparse as sp\n",
    "\n",
    "word_vectorizer = None\n",
    "# TODO: When using inference pipelines, it's important\n",
    "# to reduce the size of the data that will be transfered\n",
    "# from one container to another\n",
    "def to_sparse(text):\n",
    "    data,indices = text.split('|')\n",
    "    data = [float(i) for i in data.split(';')]\n",
    "    cols = [int(i) for i in indices.split(';')]\n",
    "    return data,cols\n",
    "\n",
    "# inference functions ---------------\n",
    "def model_fn(model_dir):\n",
    "    clf = joblib.load(os.path.join(model_dir, \"model.joblib\"))\n",
    "    return clf\n",
    "\n",
    "def input_fn(request_body, request_content_type):\n",
    "    global word_vectorizer\n",
    "    \"\"\"An input_fn that loads a pickled numpy array\"\"\"\n",
    "    \n",
    "    if request_content_type == \"text/plain\":\n",
    "        print(os.getcwd())\n",
    "        if word_vectorizer is None:\n",
    "            word_vectorizer = joblib.load(os.path.join( 'opt', 'ml', 'model', 'word_vectorizer.joblib'))\n",
    "            \n",
    "        return word_vectorizer.transform([request_body])\n",
    "    else:\n",
    "        # Handle other content-types here or raise an Exception\n",
    "        # if the content type is not supported.\n",
    "        pass\n",
    "    \n",
    "# This has a better performance for post processing the data\n",
    "def output_fn(prediction, content_type):\n",
    "    if content_type == \"application/json\":\n",
    "        return json.dumps(prediction.tolist())\n",
    "    else:\n",
    "        raise Exception( \"output_fn: Invalid content-type: %s\" % content_type )\n",
    "\n",
    "def train(args):\n",
    "    print('reading data')\n",
    "    #with open(os.path.join(args.model_dir, 'properties.txt'), 'w' ) as prop:\n",
    "    #    prop.write(str(args.vocab_size))\n",
    "\n",
    "    train_df = pd.read_csv(os.path.join(args.train, args.train_file))\n",
    "    validation_df = pd.read_csv(os.path.join(args.validation, args.validation_file))\n",
    "    #print(np.concatenate((train_df.product_name.values, validation_df.product_name.values), axis=0))\n",
    "    print('Tokenizing...')\n",
    "    # tranlating table for removing accents\n",
    "    accents = \"\".maketrans(\"áàãâéêíóôõúüçÁÀÃÂÉÊÍÓÔÕÚÜÇ\", \"aaaaeeiooouucAAAAEEIOOOUUC\")\n",
    "\n",
    "    # loading stopwords without accents\n",
    "    with open(\"stopwords.txt\", \"r\") as file:\n",
    "        stopwords = list(map(lambda x:x.strip().translate(accents),file.readlines()))\n",
    "\n",
    "    word_vectorizer = TfidfVectorizer(ngram_range=(1,2), analyzer='word', stop_words=stopwords, token_pattern='[a-zA-Z]+')\n",
    "    word_vectorizer.fit(\n",
    "        np.concatenate((train_df.product_name.values, validation_df.product_name.values), axis=0)\n",
    "    )\n",
    "    joblib.dump(word_vectorizer, os.path.join(args.model_dir, 'word_vectorizer.joblib'))\n",
    "    \n",
    "    X_train = word_vectorizer.transform(train_df.product_name.values)\n",
    "    X_val = word_vectorizer.transform(validation_df.product_name.values)\n",
    "    print(\"Shapes (train/val)\",X_train.shape, X_val.shape)\n",
    "    y_train = train_df.category.astype('category').cat.codes\n",
    "    y_val = validation_df.category.astype('category').cat.codes\n",
    "    \n",
    "    print('building training and testing datasets')\n",
    "\n",
    "    # train\n",
    "    print('training model')\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=args.n_estimators,\n",
    "        min_samples_leaf=args.min_samples_leaf,\n",
    "        n_jobs=-1,verbose=True)\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # print abs error\n",
    "    print('validating model')\n",
    "    abs_err = np.abs(model.predict(X_val) - y_val)\n",
    "\n",
    "    # print couple perf metrics\n",
    "    for q in [10, 50, 90]:\n",
    "        print('AE-at-' + str(q) + 'th-percentile: '\n",
    "              + str(np.percentile(a=abs_err, q=q)))\n",
    "        \n",
    "    # persist model\n",
    "    path = os.path.join(args.model_dir, \"model.joblib\")\n",
    "    joblib.dump(model, path)\n",
    "    print('model persisted at ' + path)\n",
    "    print(args.min_samples_leaf)\n",
    "    \n",
    "        \n",
    "if __name__ =='__main__':\n",
    "\n",
    "    print('extracting arguments')\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    # hyperparameters sent by the client are passed as command-line arguments to the script.\n",
    "    # to simplify the demo we don't use all sklearn RandomForest hyperparameters\n",
    "    parser.add_argument('--n-estimators', type=int, default=10)\n",
    "    parser.add_argument('--min-samples-leaf', type=int, default=3)\n",
    "\n",
    "    # Data, model, and output directories\n",
    "    parser.add_argument('--model-dir', type=str, default=os.environ.get('SM_MODEL_DIR'))\n",
    "    parser.add_argument('--train', type=str, default=os.environ.get('SM_CHANNEL_TRAIN'))\n",
    "    parser.add_argument('--validation', type=str, default=os.environ.get('SM_CHANNEL_VALIDATION'))\n",
    "    parser.add_argument('--train-file', type=str, default='train.csv')\n",
    "    parser.add_argument('--validation-file', type=str, default='test.csv')\n",
    "    \n",
    "    args, _ = parser.parse_known_args()\n",
    "\n",
    "    train(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A basic local test to see if the training process is ok"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir -p opt/ml/model\n",
    "!python src/products.py --n-estimators 100 \\\n",
    "                    --min-samples-leaf 2 \\\n",
    "                    --model-dir opt/ml/model/ \\\n",
    "                    --train data/ \\\n",
    "                    --validation data/ \\\n",
    "                    --train-file products_cat_train.csv \\\n",
    "                    --validation-file products_cat_test.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0,'src')\n",
    "from importlib import reload\n",
    "import products as p\n",
    "import random\n",
    "p = reload(p)\n",
    "\n",
    "sample = X_test[random.randint(0,len(X_test))]\n",
    "#os.environ['SM_MODEL_DIR'] =  'model'\n",
    "model = p.model_fn('model')\n",
    "payload = p.input_fn(sample, 'text/plain')\n",
    "pred = model.predict(payload)\n",
    "out = p.output_fn(pred,\"application/json\")\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ok, now let's wrap everything and Train our model using SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import boto3\n",
    "\n",
    "from sagemaker.sklearn import SKLearn\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "prefix='products'\n",
    "# Retrieve the default bucket\n",
    "sagemaker_session = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upload the dataset to an S3 bucket\n",
    "input_train = sagemaker_session.upload_data(path='data/products_cat_train.csv', key_prefix='%s/data' % prefix)\n",
    "input_test = sagemaker_session.upload_data(path='data/products_cat_test.csv', key_prefix='%s/data' % prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = sagemaker.session.s3_input(s3_data=input_train,content_type=\"csv\")\n",
    "test_data = sagemaker.session.s3_input(s3_data=input_test,content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train my estimator\n",
    "sklearn_estimator = SKLearn(entry_point='products.py',\n",
    "                            source_dir='src',\n",
    "                            train_instance_type='ml.c5.4xlarge',\n",
    "                            framework_version='0.20.0',\n",
    "                            metric_definitions=[\n",
    "                                {'Name': 'median-AE',\n",
    "                                 'Regex': \"AE-at-50th-percentile: ([0-9.]+).*$\"}\n",
    "                            ],\n",
    "                            role=role,\n",
    "                            hyperparameters={\n",
    "                                'n-estimators': 100,\n",
    "                                'min-samples-leaf': 2,\n",
    "                                'train-file': 'products_cat_train.csv',\n",
    "                                'validation-file' : 'products_cat_test.csv'\n",
    "                            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_estimator.fit({'train': train_data, 'validation': test_data, })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deploy my estimator to a SageMaker Endpoint and get a Predictor\n",
    "endpoint_name=None\n",
    "predictor = sklearn_estimator.deploy( \n",
    "    endpoint_name=endpoint_name, \n",
    "    instance_type='ml.c5.xlarge', \n",
    "    initial_instance_count=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We now have a trained model and a real-time endpoint deployed.\n",
    "Let's do a basic test and then check the model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "predictor.serializer = None\n",
    "predictor.deserializer = None\n",
    "predictor.content_type = 'text/plain'\n",
    "predictor.accept = 'application/json'\n",
    "\n",
    "idx = random.randint(0,len(X_test))\n",
    "sample = X_test[idx]\n",
    "resp = json.loads(predictor.predict(sample))\n",
    "print(\"Prod[{}], Cat[{}], Correct? {}\".format( sample, resp[0], resp[0]==y_test[idx]) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test the whole 'TEST' portion of the dataset to create the confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "predictions = [json.loads(predictor.predict(i))[0] for i in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "score = f1_score(y_test,predictions,average='micro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('F1 Score(micro): %.4f' % (score * 100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cnf_matrix = normalize(confusion_matrix(y_test, predictions))\n",
    "f, ax = plt.subplots(figsize=(15, 8))\n",
    "\n",
    "sns.heatmap(cnf_matrix, annot=True, fmt=\"f\", mask=np.zeros_like(cnf_matrix, dtype=np.bool), \n",
    "            cmap=sns.diverging_palette(220, 10, as_cmap=True),\n",
    "            square=True, ax=ax)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
