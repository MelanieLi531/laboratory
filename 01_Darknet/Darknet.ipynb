{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the docker images for Darknet (yolo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "repo_name=<<YOUR ECR URL>> # ie. \"<<your account id here>>.dkr.ecr.us-east-1.amazonaws.com\"\n",
    "region_name=<<SERVICE REGION>> # ie. 'us-east-1'\n",
    "\n",
    "\n",
    "darknet_gpu=\"darknet:gpu-1.0\"\n",
    "darknet_cpu=\"darknet:cpu-1.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_image(dockerfile, repo_name, tag_name):\n",
    "    !cd Docker && sudo docker build -f $dockerfile -t $tag_name .\n",
    "    !cd Docker && sudo docker tag $tag_name $repo_name/$tag_name\n",
    "    login=!aws ecr get-login --no-include-email\n",
    "    login=login[0]\n",
    "    !eval \"sudo $login\"\n",
    "    !sudo docker push $repo_name/$tag_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First the GPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_image(\"Dockerfile.gpu\", repo_name, darknet_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now, the CPU version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_image(\"Dockerfile.cpu\", repo_name, darknet_cpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now, let's deploy a pre-trained yolo model, for Object Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import boto3\n",
    "import re\n",
    "import os\n",
    "import time\n",
    "\n",
    "from time import gmtime, strftime\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "import sagemaker\n",
    "\n",
    "# Get the current Sagemaker session\n",
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# 1. Obtaining the role you already configured for Sagemaker when you setup\n",
    "# your Instance notebook (https://docs.aws.amazon.com/sagemaker/latest/dg/gs-setup-working-env.html)\n",
    "role = get_execution_role()\n",
    "\n",
    "# 2. The S3 Bucket that will store the dataset and the trained model\n",
    "# It was already defined above, while we uploaded the RecordIO files to the S3 bucket.\n",
    "\n",
    "# 3. Select the correct Docker image with the Image Classification algorithm\n",
    "containers = {region_name: '%s/%s' % ( repo_name, darknet_gpu) }\n",
    "training_image = containers[boto3.Session().region_name]\n",
    "print(training_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Here we will download the pre-trained model and create a package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "mkdir -p /tmp/model\n",
    "cd /tmp/model\n",
    "\n",
    "curl https://pjreddie.com/media/files/yolov3.weights -o model.weights\n",
    "curl https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/coco.data -o model.data\n",
    "curl https://raw.githubusercontent.com/pjreddie/darknet/master/cfg/yolov3.cfg -o model.cfg\n",
    "\n",
    "tar -czvf ../model.tar.gz ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Upload the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_data = sagemaker_session.upload_data(path='/tmp/model.tar.gz', key_prefix='data/yolov3')\n",
    "print(model_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleaning the downloaded files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!rm -rf /tmp/model.tar.gz /tmp/model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploying the model/endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create an Mxnet Estimator\n",
    "m = sagemaker.model.Model(image=training_image, model_data=model_data, role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Publishes the model. It takes around 8mins\n",
    "predictor = m.deploy(initial_instance_count=1, instance_type='ml.p2.xlarge')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import boto3\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sagemaker.predictor import json_serializer, json_deserializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(filename):\n",
    "    img = open(filename, 'rb').read()\n",
    "    sm = boto3.client('sagemaker-runtime')\n",
    "    response = sm.invoke_endpoint(\n",
    "        EndpointName=endpoint_name,\n",
    "        ContentType='application/x-image',\n",
    "        Body=bytearray(img)\n",
    "    )\n",
    "    resp = json_deserializer(response['Body'], response['ContentType']) \n",
    "    return resp['detections']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def render_bboxes(filename):\n",
    "    bboxes = predict(filename)\n",
    "    img = cv2.imread(filename)\n",
    "    h,w,_ = img.shape\n",
    "    \n",
    "    thick = int((h + w) // 400)\n",
    "    for i in range(len(bboxes)):\n",
    "        category = bboxes[i][0]\n",
    "        confidence = bboxes[i][1]\n",
    "        bbox = bboxes[i][2]\n",
    "        \n",
    "        bW = int(bbox[2])\n",
    "        bH = int(bbox[3])\n",
    "        \n",
    "        x1 = int(bbox[0]-bW/2)\n",
    "        y1 = int(bbox[1]-bH/2)\n",
    "        if x1 < 0: \n",
    "            x1 = 0 \n",
    "        if y1 < 0:\n",
    "            y1 = 0\n",
    "        \n",
    "        x2 = int(x1+bW)\n",
    "        y2 = int(y1+bH)\n",
    "    \n",
    "        cv2.rectangle(img, (x1, y1), (x2, y2), (255,0,0), thick)\n",
    "        cv2.putText(img, \"%s (%f)\" %( category, confidence),(x1, y1), 0, 0.5, (0,0,255), thick//2)\n",
    "        \n",
    "\n",
    "    plt.figure(figsize=(12,8))\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.imshow(img)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's get a sample and run it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://qph.fs.quoracdn.net/main-qimg-99262df5d519ae1c5196f7626249583b -o /tmp/dog.jpg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "render_bboxes('/tmp/dog.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Delete the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "sagemaker.Session().delete_endpoint(endpoint_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
